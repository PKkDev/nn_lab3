tutorial

https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91

https://github.com/sergiovirahonda/TweetsSentimentAnalysis/blob/main/TweetsSentimentPredictions.ipynb

https://www.tensorflow.org/tutorials/structured_data/time_series#recurrent_neural_network

https://www.tensorflow.org/guide/keras/rnn

dataset
http://study.mokoron.com/
https://github.com/ahlesen/RuTweetCorp/tree/master/data

База данных состоит из 12 столбцов:
– id: уникальный номер сообщения в системе twitter;
– tdate: дата публикации сообщения (твита);
– tmane: имя пользователя, опубликовавшего сообщение;
– ttext:  текст сообщения (твита);
– ttype: поле в котором в дальнейшем будет указано к кому классу относится твит (положительный, отрицательный, нейтральный);
– trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;
– tfav: число сколько раз данное сообщение было добавлено в избранное другими пользователями;
– tstcount: число всех сообщений пользователя в сети twitter;
– tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);
– tfrien: количество друзей пользователя (те люди, которых читает пользователь);
– listcount: количество листов-подписок в которые добавлен твиттер-пользователь.


# Embedding - слой встраивания
# слой встраивания — это словарь, который связывает целочисленные индексы с плотными векторами, он возвращает 3D-тензор формы с плавающей запятой
# количество возможных токенов - max_words
# размерность встраиваний- 40

# двунаправленный слой
# максимизирует чувствительность порядка RNN: по сути, он состоит из двух RNN (LSTM или GRU), которые обрабатывают входную последовательность в одном другом направлении, чтобы окончательно объединить представления
# другими словами, один из слоев интерпретирует последовательности в хронологическом порядке, а второй — в антихронологическом порядке

# LSTM
# 20 - количество скрытых единиц внутри слоя = размерность выходного пространства
# Dropout - наиболее эффективный и наиболее часто используемый метод регуляризации для сетей и состоит из случайного отключения скрытых единиц во время обучения

# Dense
# 2 - выхода
# softmax в качестве функции активации в конечном слое

# RMSprop / Adam - оптимизатор = это просто механизм, который постоянно вычисляет градиент потерь и определяет, как двигаться против функции потерь, чтобы найти ее глобальные минимумы и, следовательно, найти лучшие параметры сети (ядро модели и веса ее смещения)
# categorical_crossentropy - функция потерь